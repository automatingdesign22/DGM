Base Model: The feature extractor is a PointNet model consisting of a 3-layer MLP (64, 128, l) with weight sharing. Each layer is followed by a ReLU activation function and a batch normalization layer. The segmentation module follows a similar architecture (64, 32, 16, k) with weight sharing and softmax function at the end and is trained with a classification loss. More complex architectures can be used for more complex input data. The decoder generates a point cloud model with three fully connected layers (1024, 2048, N × 3)： the first two layers are followed by a ReLU function. The system was trained using the Chamfer distance as the reconstruction loss and the cross-entropy loss as the segmentation loss. The Adam optimizer uses a learning rate of 5 × 10−4 for 1000 epochs. The latent space WGAN-based architecture uses point feature data as input and output. The generator is a 3-layer MLP (128, 128, l) for generating point features corresponding to k functional requirements, and the discriminator mirrors the generator. The generator input is a 128-dimensional vector sampled from a normal distribution. L-WGAN has been trained using the Adam optimizer with learning rates of 5 × 10−4 and 1 × 10−4 for the generator and discriminator, respectively. After every 100 epochs of training, the generator samples are evaluated, the top 10% of the data that best satisfies the process variables are selected to replace the same amount of original data, and an additional 20 epochs are trained. In the article, l is 128, and N is 2048.
